{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import logging\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Grammy dataframe: \n",
      "   year                              title              published_at  \\\n",
      "0  2019  62nd Annual GRAMMY Awards  (2019) 2020-05-19 12:10:28+00:00   \n",
      "1  2019  62nd Annual GRAMMY Awards  (2019) 2020-05-19 12:10:28+00:00   \n",
      "2  2019  62nd Annual GRAMMY Awards  (2019) 2020-05-19 12:10:28+00:00   \n",
      "3  2019  62nd Annual GRAMMY Awards  (2019) 2020-05-19 12:10:28+00:00   \n",
      "4  2019  62nd Annual GRAMMY Awards  (2019) 2020-05-19 12:10:28+00:00   \n",
      "\n",
      "                 updated_at            category     nominee         artist  \\\n",
      "0 2020-05-19 12:10:28+00:00  Record Of The Year     Bad Guy  Billie Eilish   \n",
      "1 2020-05-19 12:10:28+00:00  Record Of The Year     Hey, Ma       Bon Iver   \n",
      "2 2020-05-19 12:10:28+00:00  Record Of The Year     7 rings  Ariana Grande   \n",
      "3 2020-05-19 12:10:28+00:00  Record Of The Year  Hard Place         H.E.R.   \n",
      "4 2020-05-19 12:10:28+00:00  Record Of The Year        Talk         Khalid   \n",
      "\n",
      "                                             workers  winner  \n",
      "0  Finneas O'Connell, producer; Rob Kinelski & Fi...    True  \n",
      "1  BJ Burton, Brad Cook, Chris Messina & Justin V...    True  \n",
      "2  Charles Anderson, Tommy Brown, Michael Foster ...    True  \n",
      "3  Rodney “Darkchild” Jerkins, producer; Joseph H...    True  \n",
      "4  Disclosure & Denis Kosiak, producers; Ingmar C...    True  \n",
      "INFO:root:Spotify dataframe: \n",
      "   Unnamed: 0                track_id                 artists  \\\n",
      "0           0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
      "1           1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
      "2           2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
      "3           3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
      "4           4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
      "\n",
      "                                          album_name  \\\n",
      "0                                             Comedy   \n",
      "1                                   Ghost (Acoustic)   \n",
      "2                                     To Begin Again   \n",
      "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
      "4                                            Hold On   \n",
      "\n",
      "                   track_name  popularity  duration_ms  explicit  \\\n",
      "0                      Comedy          73       230666     False   \n",
      "1            Ghost - Acoustic          55       149610     False   \n",
      "2              To Begin Again          57       210826     False   \n",
      "3  Can't Help Falling In Love          71       201933     False   \n",
      "4                     Hold On          82       198853     False   \n",
      "\n",
      "   danceability  energy  key  loudness  mode  speechiness  instrumentalness  \\\n",
      "0         0.676  0.4610    1    -6.746     0       0.1430          0.000001   \n",
      "1         0.420  0.1660    1   -17.235     1       0.0763          0.000006   \n",
      "2         0.438  0.3590    0    -9.734     1       0.0557          0.000000   \n",
      "3         0.266  0.0596    0   -18.515     1       0.0363          0.000071   \n",
      "4         0.618  0.4430    2    -9.681     1       0.0526          0.000000   \n",
      "\n",
      "   liveness  valence    tempo  time_signature track_genre  \n",
      "0    0.3580    0.715   87.917               4    acoustic  \n",
      "1    0.1010    0.267   77.489               4    acoustic  \n",
      "2    0.1170    0.120   76.332               4    acoustic  \n",
      "3    0.1320    0.143  181.740               3    acoustic  \n",
      "4    0.0829    0.167  119.949               4    acoustic  \n",
      "INFO:root:Dataframes loaded successfully\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def load_all_dataframes():\n",
    "    try:\n",
    "        grammy_df = pd.read_pickle('./grammy_ready_df.pkl')\n",
    "        spotify_df = pd.read_pickle('./spotify_ready_df.pkl')\n",
    "        \n",
    "        logging.info(f\"Grammy dataframe: \\n{grammy_df.head(5)}\")\n",
    "        logging.info(f\"Spotify dataframe: \\n{spotify_df.head(5)}\")\n",
    "    \n",
    "        \n",
    "        logging.info(\"Dataframes loaded successfully\")\n",
    "        \n",
    "        return grammy_df, spotify_df\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading dataframes: {e}\")\n",
    "\n",
    "grammy, spotify = load_all_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Merging dataframes...\n",
      "INFO:root:Unique values in 'winner' column: [ True]\n",
      "INFO:root:Total records with value 'True': 23851\n",
      "INFO:root:Column 'winner' removed from the dataset.\n",
      "INFO:root:Merge completed successfully.\n"
     ]
    }
   ],
   "source": [
    "def merge(grammy_df, spotify_df):\n",
    "    try:\n",
    "        logging.info(\"Merging dataframes...\")\n",
    "        \n",
    "        merged_df = pd.merge(grammy_df, spotify_df, left_on='artist', right_on='artists', how='inner')\n",
    "\n",
    "        merged_df['artist'] = merged_df['artist'].combine_first(merged_df['artists'])\n",
    "        \n",
    "        if 'winner' in merged_df.columns:\n",
    "            valores_unicos = merged_df['winner'].unique()\n",
    "            logging.info(f\"Unique values in 'winner' column: {valores_unicos}\")\n",
    "\n",
    "            conteo_registros = merged_df['winner'].value_counts()\n",
    "            for valor, conteo in conteo_registros.items():\n",
    "                logging.info(f\"Total records with value '{valor}': {conteo}\")\n",
    "\n",
    "            merged_df = merged_df.drop(columns=['winner'])\n",
    "            logging.info(\"Column 'winner' removed from the dataset.\")\n",
    "\n",
    "        merged_df.drop(columns=['artists','liveness','time_signature', 'loudness','mode'], inplace=True)\n",
    "\n",
    "        logging.info(\"Merge completed successfully.\")\n",
    "        return merged_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during dataframe merge: {e}\")\n",
    "\n",
    "\n",
    "df_merge = merge(grammy, spotify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(mergedf):\n",
    "    try:\n",
    "        # num_duplicates = mergedf.duplicated().sum()\n",
    "        # logging.info(f\"The total of duplicates in the dataframe is: {num_duplicates}\")\n",
    "        mergedf.to_csv('../Clean-Data/merge_df.csv', index=False)\n",
    "        logging.info(\"Dataframe saved as CSV successfully.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving dataframe as CSV: {e}\")\n",
    "        \n",
    "save_csv(df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_DB(df):\n",
    "    try:\n",
    "        load_dotenv()\n",
    "\n",
    "        localhost = os.getenv('LOCALHOST')\n",
    "        port = os.getenv('PORT')\n",
    "        nameDB = os.getenv('DB_NAME')\n",
    "        userDB = os.getenv('DB_USER')\n",
    "        passDB = os.getenv('DB_PASS')\n",
    "\n",
    "        engine = create_engine(f'postgresql+psycopg2://{userDB}:{passDB}@{localhost}:{port}/{nameDB}')\n",
    "        inspector = inspect(engine)\n",
    "\n",
    "        with engine.connect() as connection:\n",
    "            logging.info(\"Successfully connected to the database.\")\n",
    "            \n",
    "            try:\n",
    "                df.to_sql('data_merge', engine, if_exists='replace', index=False)\n",
    "                logging.info(\"Table 'data_merge' added.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error adding data: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error connecting to the database: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        engine.dispose()\n",
    "        logging.info(\"Database connection closed.\")\n",
    "        \n",
    "save_DB(df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DataFrame saved as CSV successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=241896318925-ktad4foffvmcujon4e29vhr73psf082p.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:oauth2client.client:Successfully retrieved access token\n",
      "INFO:googleapiclient.discovery_cache:file_cache is only supported with oauth2client<4.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful.\n",
      "Archivo 'df_merge.csv' subido correctamente a Google Drive.\n"
     ]
    }
   ],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import logging\n",
    "\n",
    "def authenticate():\n",
    "    gauth = GoogleAuth()\n",
    "\n",
    "    gauth.LoadClientConfigFile(\"../client_secret.json\")\n",
    "    \n",
    "    gauth.LocalWebserverAuth()\n",
    "    \n",
    "    return gauth\n",
    "\n",
    "def save_drive(df, file_name='df_merge.csv', folder_id=None):\n",
    "    try:\n",
    "        temp_file_path = f\"./{file_name}\"\n",
    "        df.to_csv(temp_file_path, index=False)\n",
    "        logging.info(\"DataFrame saved as CSV successfully.\")\n",
    "\n",
    "        gauth = authenticate()\n",
    "        drive = GoogleDrive(gauth)\n",
    "\n",
    "        file = drive.CreateFile({'title': file_name, 'parents': [{'id': folder_id}] if folder_id else []})\n",
    "        file.SetContentFile(temp_file_path)\n",
    "        file.Upload()\n",
    "\n",
    "        print(f\"Archivo '{file_name}' subido correctamente a Google Drive.\")\n",
    "\n",
    "        os.remove(temp_file_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al subir el archivo a Google Drive: {e}\")\n",
    "\n",
    "save_drive(df_merge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop2-JuwIq9Fz-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
